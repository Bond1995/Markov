Training model=base
{'config_format': 'markov', 'batch_size': 16, 'acc_steps': 1, 'seed': 0, 'device': device(type='cuda', index=0), 'iterations': 1000, 'lr': 0.002, 'warmup_percent': 0.02, 'weight_decay': 0.001, 'beta1': 0.9, 'beta2': 0.95, 'scheduler': 'cos', 'opt': 'adamw', 'eval_freq': 1, 'results_base_folder': './exps', 'grad_clip': 0.0, 'dataset': 'markov', 'vocab_size': 2, 'data_in_ram': False, 'model': 'base', 'use_pretrained': 'none', 'dropout': 0, 'n_head': 1, 'n_layer': 1, 'n_embd': 8, 'sequence_length': 1024, 'dtype': torch.float16, 'bias': False, 'no_compile': True, 'wandb': True, 'wandb_project': 'bias-test', 'wandb_run_prefix': 'none', 'eval_seq_prefix': '0', 'distributed_backend': None, 'p': 0.5, 'q': 0.5, 'order': 1, 'chain': 'random', 'memory': -1, 'initial': 'uniform', 'init': 'base', 'init_value': 1.0, 'world_size': 1}
9002
Markov transition matrix:
tensor([[0.9866, 0.0134],
        [0.4304, 0.5696]], device='cuda:0')
Traceback (most recent call last):
  File "/mlbio_scratch/ekbote/Markov/Markov-LLM-depth/src/main.py", line 151, in <module>
    main(args)
  File "/mlbio_scratch/ekbote/Markov/Markov-LLM-depth/src/main.py", line 133, in main
    stats = train(model, opt, P, order, scheduler, args.iterations, args.acc_steps, args.batch_size, args.sequence_length, generator,
  File "/mlbio_scratch/ekbote/Markov/Markov-LLM-depth/src/optim/base.py", line 35, in train_base
    outputs = model(x, targets=y)
  File "/home/ekbote/.conda/envs/torch-2.4/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/ekbote/.conda/envs/torch-2.4/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "/mlbio_scratch/ekbote/Markov/Markov-LLM-depth/src/models/base.py", line 302, in forward
    x, att_mean, att_std = block(x, get_att=get_att)
  File "/home/ekbote/.conda/envs/torch-2.4/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/ekbote/.conda/envs/torch-2.4/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "/mlbio_scratch/ekbote/Markov/Markov-LLM-depth/src/models/base.py", line 210, in forward
    z, att_mean, att_std = self.attn(self.ln_1(x), get_att=get_att)
  File "/home/ekbote/.conda/envs/torch-2.4/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/ekbote/.conda/envs/torch-2.4/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "/mlbio_scratch/ekbote/Markov/Markov-LLM-depth/src/models/base.py", line 107, in forward
    self.log_energy_and_weights(proj_weight, f"proj-id{self.id}-iter{self.iter}")
TypeError: CausalSelfAttention.log_energy_and_weights() missing 1 required positional argument: 'iter'