Training model=base
{'config_format': 'markov', 'batch_size': 16, 'acc_steps': 1, 'seed': 2, 'device': device(type='cuda', index=0), 'iterations': 10000, 'lr': 0.002, 'warmup_percent': 0.02, 'weight_decay': 0.001, 'beta1': 0.9, 'beta2': 0.95, 'scheduler': 'cos', 'opt': 'adamw', 'eval_freq': 1, 'results_base_folder': './exps', 'grad_clip': 0.0, 'dataset': 'markov', 'vocab_size': 2, 'data_in_ram': False, 'model': 'base', 'use_pretrained': 'none', 'dropout': 0, 'n_head': 1, 'n_layer': 2, 'n_embd': 16, 'sequence_length': 128, 'dtype': torch.float16, 'bias': False, 'no_compile': True, 'wandb': True, 'wandb_project': 'bias-test', 'wandb_run_prefix': 'none', 'eval_seq_prefix': '0', 'distributed_backend': None, 'p': 0.5, 'q': 0.5, 'order': 1, 'chain': 'random', 'memory': -1, 'initial': 'uniform', 'init': 'base', 'init_value': 1.0, 'world_size': 1}
8306
Markov transition matrix:
tensor([[0.3818, 0.6182],
        [0.8917, 0.1083]], device='cuda:0')
Traceback (most recent call last):
  File "/mlbio_scratch/ekbote/Markov/Markov-LLM-depth/src/main.py", line 151, in <module>
    main(args)
  File "/mlbio_scratch/ekbote/Markov/Markov-LLM-depth/src/main.py", line 133, in main
    stats = train(model, opt, P, order, scheduler, args.iterations, args.acc_steps, args.batch_size, args.sequence_length, generator,
  File "/mlbio_scratch/ekbote/Markov/Markov-LLM-depth/src/optim/base.py", line 32, in train_base
    x, y = get_batch(P, order, sequence_length, batch_size, generator, extra_args, device=extra_args.device)
  File "/mlbio_scratch/ekbote/Markov/Markov-LLM-depth/src/optim/utils.py", line 37, in get_batch
    data[:,i] = get_next_symbols(P, order, data[:,i-order:i])
  File "/mlbio_scratch/ekbote/Markov/Markov-LLM-depth/src/optim/utils.py", line 45, in get_next_symbols
    idx = data @ powers
RuntimeError: CUDA error: CUBLAS_STATUS_NOT_INITIALIZED when calling `cublasCreate(handle)`