Training model=base
{'config_format': 'markov', 'batch_size': 16, 'acc_steps': 1, 'seed': 0, 'device': device(type='cuda', index=0), 'iterations': 1000, 'lr': 0.002, 'warmup_percent': 0.02, 'weight_decay': 0.001, 'beta1': 0.9, 'beta2': 0.95, 'scheduler': 'cos', 'opt': 'adamw', 'eval_freq': 1, 'results_base_folder': './exps', 'grad_clip': 0.0, 'dataset': 'markov', 'vocab_size': 2, 'data_in_ram': False, 'model': 'base', 'use_pretrained': 'none', 'dropout': 0, 'n_head': 1, 'n_layer': 1, 'n_embd': 8, 'sequence_length': 1024, 'dtype': torch.float16, 'bias': False, 'no_compile': True, 'wandb': True, 'wandb_project': 'bias-test', 'wandb_run_prefix': 'none', 'eval_seq_prefix': '0', 'distributed_backend': None, 'p': 0.5, 'q': 0.5, 'order': 1, 'chain': 'random', 'memory': -1, 'initial': 'uniform', 'init': 'base', 'init_value': 1.0, 'world_size': 1}
9002
Markov transition matrix:
tensor([[0.1866, 0.8134],
        [0.9647, 0.0353]], device='cuda:0')
1 [train] loss=0.739 [val] loss=0.739, pp=2.09, acc=0.145325 [time per itr] 2103.10ms [lr] 0.00003
2 [train] loss=0.739 [val] loss=0.739, pp=2.09, acc=0.143945 [time per itr] 266.12ms [lr] 0.00007
3 [train] loss=0.739 [val] loss=0.738, pp=2.09, acc=0.146149 [time per itr] 263.85ms [lr] 0.00014
4 [train] loss=0.738 [val] loss=0.737, pp=2.09, acc=0.146716 [time per itr] 264.92ms [lr] 0.00023
5 [train] loss=0.738 [val] loss=0.735, pp=2.09, acc=0.150238 [time per itr] 268.73ms [lr] 0.00034
6 [train] loss=0.735 [val] loss=0.733, pp=2.08, acc=0.154181 [time per itr] 270.84ms [lr] 0.00047
7 [train] loss=0.733 [val] loss=0.730, pp=2.07, acc=0.161072 [time per itr] 264.61ms [lr] 0.00061
8 [train] loss=0.730 [val] loss=0.726, pp=2.07, acc=0.169537 [time per itr] 266.91ms [lr] 0.00077
9 [train] loss=0.726 [val] loss=0.721, pp=2.06, acc=0.179065 [time per itr] 264.36ms [lr] 0.00093
10 [train] loss=0.721 [val] loss=0.717, pp=2.05, acc=0.196771 [time per itr] 331.20ms [lr] 0.00109
11 [train] loss=0.716 [val] loss=0.712, pp=2.04, acc=0.214563 [time per itr] 267.36ms [lr] 0.00125
12 [train] loss=0.712 [val] loss=0.708, pp=2.03, acc=0.237842 [time per itr] 275.58ms [lr] 0.00141
13 [train] loss=0.708 [val] loss=0.704, pp=2.02, acc=0.258246 [time per itr] 263.16ms [lr] 0.00155
14 [train] loss=0.704 [val] loss=0.701, pp=2.02, acc=0.296423 [time per itr] 264.52ms [lr] 0.00168
15 [train] loss=0.701 [val] loss=0.698, pp=2.01, acc=0.347675 [time per itr] 265.28ms [lr] 0.00179
16 [train] loss=0.698 [val] loss=0.696, pp=2.01, acc=0.432324 [time per itr] 266.83ms [lr] 0.00188
17 [train] loss=0.696 [val] loss=0.695, pp=2.00, acc=0.491595 [time per itr] 267.31ms [lr] 0.00195
18 [train] loss=0.695 [val] loss=0.694, pp=2.00, acc=0.521906 [time per itr] 263.95ms [lr] 0.00199
19 [train] loss=0.694 [val] loss=0.693, pp=2.00, acc=0.537726 [time per itr] 266.04ms [lr] 0.00200
20 [train] loss=0.693 [val] loss=0.693, pp=2.00, acc=0.541974 [time per itr] 265.29ms [lr] 0.00200
21 [train] loss=0.693 [val] loss=0.693, pp=2.00, acc=0.542322 [time per itr] 263.09ms [lr] 0.00200
22 [train] loss=0.692 [val] loss=0.692, pp=2.00, acc=0.542633 [time per itr] 263.49ms [lr] 0.00200
23 [train] loss=0.692 [val] loss=0.692, pp=2.00, acc=0.542700 [time per itr] 262.59ms [lr] 0.00200
24 [train] loss=0.692 [val] loss=0.692, pp=2.00, acc=0.543353 [time per itr] 262.48ms [lr] 0.00200
25 [train] loss=0.692 [val] loss=0.692, pp=2.00, acc=0.542523 [time per itr] 264.13ms [lr] 0.00200
26 [train] loss=0.691 [val] loss=0.691, pp=2.00, acc=0.543719 [time per itr] 262.42ms [lr] 0.00200
27 [train] loss=0.692 [val] loss=0.691, pp=2.00, acc=0.542365 [time per itr] 262.34ms [lr] 0.00200
28 [train] loss=0.691 [val] loss=0.691, pp=2.00, acc=0.543005 [time per itr] 270.34ms [lr] 0.00200
29 [train] loss=0.691 [val] loss=0.691, pp=2.00, acc=0.542743 [time per itr] 266.98ms [lr] 0.00200
30 [train] loss=0.690 [val] loss=0.691, pp=1.99, acc=0.542407 [time per itr] 267.76ms [lr] 0.00200
31 [train] loss=0.690 [val] loss=0.690, pp=1.99, acc=0.543213 [time per itr] 301.95ms [lr] 0.00200
32 [train] loss=0.690 [val] loss=0.690, pp=1.99, acc=0.542126 [time per itr] 262.19ms [lr] 0.00200
33 [train] loss=0.690 [val] loss=0.689, pp=1.99, acc=0.542780 [time per itr] 266.29ms [lr] 0.00200
34 [train] loss=0.690 [val] loss=0.689, pp=1.99, acc=0.543134 [time per itr] 262.94ms [lr] 0.00200
35 [train] loss=0.689 [val] loss=0.688, pp=1.99, acc=0.543201 [time per itr] 262.70ms [lr] 0.00200
36 [train] loss=0.688 [val] loss=0.688, pp=1.99, acc=0.542706 [time per itr] 264.50ms [lr] 0.00200
37 [train] loss=0.687 [val] loss=0.687, pp=1.99, acc=0.543243 [time per itr] 262.92ms [lr] 0.00200
38 [train] loss=0.687 [val] loss=0.686, pp=1.99, acc=0.543494 [time per itr] 272.76ms [lr] 0.00200
39 [train] loss=0.686 [val] loss=0.684, pp=1.98, acc=0.544397 [time per itr] 264.24ms [lr] 0.00200
40 [train] loss=0.684 [val] loss=0.682, pp=1.98, acc=0.545160 [time per itr] 264.80ms [lr] 0.00200
41 [train] loss=0.682 [val] loss=0.679, pp=1.97, acc=0.548737 [time per itr] 264.54ms [lr] 0.00200
42 [train] loss=0.679 [val] loss=0.674, pp=1.96, acc=0.554358 [time per itr] 265.29ms [lr] 0.00200
43 [train] loss=0.674 [val] loss=0.668, pp=1.95, acc=0.576709 [time per itr] 263.63ms [lr] 0.00200
44 [train] loss=0.668 [val] loss=0.660, pp=1.93, acc=0.628278 [time per itr] 266.38ms [lr] 0.00200
45 [train] loss=0.660 [val] loss=0.649, pp=1.91, acc=0.710175 [time per itr] 262.02ms [lr] 0.00200
46 [train] loss=0.650 [val] loss=0.637, pp=1.89, acc=0.781781 [time per itr] 258.45ms [lr] 0.00200
47 [train] loss=0.637 [val] loss=0.624, pp=1.87, acc=0.825037 [time per itr] 262.75ms [lr] 0.00200
48 [train] loss=0.624 [val] loss=0.611, pp=1.84, acc=0.847095 [time per itr] 258.41ms [lr] 0.00200
49 [train] loss=0.611 [val] loss=0.598, pp=1.82, acc=0.862018 [time per itr] 259.00ms [lr] 0.00200
50 [train] loss=0.598 [val] loss=0.586, pp=1.80, acc=0.869684 [time per itr] 261.05ms [lr] 0.00200
51 [train] loss=0.586 [val] loss=0.574, pp=1.78, acc=0.875800 [time per itr] 259.51ms [lr] 0.00200
52 [train] loss=0.573 [val] loss=0.564, pp=1.76, acc=0.877509 [time per itr] 261.27ms [lr] 0.00200
53 [train] loss=0.563 [val] loss=0.554, pp=1.74, acc=0.880286 [time per itr] 261.42ms [lr] 0.00200
54 [train] loss=0.554 [val] loss=0.545, pp=1.72, acc=0.879120 [time per itr] 260.99ms [lr] 0.00199
55 [train] loss=0.546 [val] loss=0.535, pp=1.71, acc=0.880835 [time per itr] 258.97ms [lr] 0.00199
56 [train] loss=0.536 [val] loss=0.527, pp=1.69, acc=0.880884 [time per itr] 262.28ms [lr] 0.00199
57 [train] loss=0.526 [val] loss=0.518, pp=1.68, acc=0.881616 [time per itr] 261.51ms [lr] 0.00199
58 [train] loss=0.518 [val] loss=0.509, pp=1.66, acc=0.882831 [time per itr] 259.13ms [lr] 0.00199
59 [train] loss=0.511 [val] loss=0.501, pp=1.65, acc=0.883582 [time per itr] 259.96ms [lr] 0.00199
60 [train] loss=0.500 [val] loss=0.493, pp=1.64, acc=0.883185 [time per itr] 261.49ms [lr] 0.00199
61 [train] loss=0.495 [val] loss=0.486, pp=1.63, acc=0.882666 [time per itr] 259.01ms [lr] 0.00199
62 [train] loss=0.487 [val] loss=0.478, pp=1.61, acc=0.883905 [time per itr] 259.49ms [lr] 0.00199
63 [train] loss=0.481 [val] loss=0.473, pp=1.60, acc=0.880634 [time per itr] 264.35ms [lr] 0.00199
64 [train] loss=0.472 [val] loss=0.464, pp=1.59, acc=0.883221 [time per itr] 265.17ms [lr] 0.00199
65 [train] loss=0.467 [val] loss=0.459, pp=1.58, acc=0.881354 [time per itr] 272.87ms [lr] 0.00199
66 [train] loss=0.461 [val] loss=0.452, pp=1.57, acc=0.882227 [time per itr] 266.37ms [lr] 0.00199
67 [train] loss=0.449 [val] loss=0.446, pp=1.56, acc=0.882159 [time per itr] 265.41ms [lr] 0.00199
68 [train] loss=0.450 [val] loss=0.440, pp=1.55, acc=0.881635 [time per itr] 264.17ms [lr] 0.00199
69 [train] loss=0.443 [val] loss=0.434, pp=1.54, acc=0.882526 [time per itr] 266.08ms [lr] 0.00199
70 [train] loss=0.435 [val] loss=0.429, pp=1.54, acc=0.882465 [time per itr] 263.61ms [lr] 0.00199
71 [train] loss=0.429 [val] loss=0.425, pp=1.53, acc=0.881281 [time per itr] 268.14ms [lr] 0.00199
72 [train] loss=0.427 [val] loss=0.419, pp=1.52, acc=0.881873 [time per itr] 267.89ms [lr] 0.00199
73 [train] loss=0.416 [val] loss=0.414, pp=1.51, acc=0.882697 [time per itr] 265.79ms [lr] 0.00199
74 [train] loss=0.407 [val] loss=0.408, pp=1.50, acc=0.883795 [time per itr] 265.09ms [lr] 0.00199
75 [train] loss=0.410 [val] loss=0.406, pp=1.50, acc=0.881592 [time per itr] 266.92ms [lr] 0.00199
76 [train] loss=0.405 [val] loss=0.401, pp=1.49, acc=0.882959 [time per itr] 262.96ms [lr] 0.00199
77 [train] loss=0.400 [val] loss=0.397, pp=1.49, acc=0.883191 [time per itr] 270.91ms [lr] 0.00199
78 [train] loss=0.397 [val] loss=0.393, pp=1.48, acc=0.882953 [time per itr] 269.29ms [lr] 0.00199
79 [train] loss=0.397 [val] loss=0.389, pp=1.48, acc=0.883270 [time per itr] 263.96ms [lr] 0.00199
80 [train] loss=0.393 [val] loss=0.385, pp=1.47, acc=0.883685 [time per itr] 265.38ms [lr] 0.00198
81 [train] loss=0.385 [val] loss=0.383, pp=1.47, acc=0.882935 [time per itr] 265.08ms [lr] 0.00198
82 [train] loss=0.389 [val] loss=0.380, pp=1.46, acc=0.882843 [time per itr] 264.63ms [lr] 0.00198
83 [train] loss=0.381 [val] loss=0.377, pp=1.46, acc=0.883002 [time per itr] 266.81ms [lr] 0.00198
84 [train] loss=0.377 [val] loss=0.375, pp=1.46, acc=0.882202 [time per itr] 266.31ms [lr] 0.00198
85 [train] loss=0.370 [val] loss=0.371, pp=1.45, acc=0.883801 [time per itr] 268.63ms [lr] 0.00198
86 [train] loss=0.371 [val] loss=0.371, pp=1.45, acc=0.881812 [time per itr] 262.83ms [lr] 0.00198
87 [train] loss=0.371 [val] loss=0.367, pp=1.44, acc=0.883337 [time per itr] 264.80ms [lr] 0.00198
88 [train] loss=0.364 [val] loss=0.365, pp=1.44, acc=0.883319 [time per itr] 265.28ms [lr] 0.00198
89 [train] loss=0.366 [val] loss=0.363, pp=1.44, acc=0.882751 [time per itr] 263.86ms [lr] 0.00198
90 [train] loss=0.366 [val] loss=0.363, pp=1.44, acc=0.881757 [time per itr] 265.60ms [lr] 0.00198
91 [train] loss=0.362 [val] loss=0.360, pp=1.43, acc=0.882111 [time per itr] 264.29ms [lr] 0.00198
92 [train] loss=0.360 [val] loss=0.358, pp=1.43, acc=0.882886 [time per itr] 264.09ms [lr] 0.00198
93 [train] loss=0.358 [val] loss=0.354, pp=1.42, acc=0.884332 [time per itr] 263.26ms [lr] 0.00198
94 [train] loss=0.356 [val] loss=0.356, pp=1.43, acc=0.881677 [time per itr] 262.69ms [lr] 0.00198
95 [train] loss=0.359 [val] loss=0.355, pp=1.43, acc=0.881525 [time per itr] 264.34ms [lr] 0.00198
96 [train] loss=0.352 [val] loss=0.351, pp=1.42, acc=0.883643 [time per itr] 266.24ms [lr] 0.00198
97 [train] loss=0.347 [val] loss=0.352, pp=1.42, acc=0.881769 [time per itr] 270.96ms [lr] 0.00198
98 [train] loss=0.355 [val] loss=0.350, pp=1.42, acc=0.882928 [time per itr] 262.11ms [lr] 0.00197
99 [train] loss=0.349 [val] loss=0.348, pp=1.42, acc=0.883246 [time per itr] 265.80ms [lr] 0.00197
100 [train] loss=0.346 [val] loss=0.346, pp=1.41, acc=0.884070 [time per itr] 263.30ms [lr] 0.00197
101 [train] loss=0.346 [val] loss=0.345, pp=1.41, acc=0.883704 [time per itr] 276.22ms [lr] 0.00197
102 [train] loss=0.353 [val] loss=0.344, pp=1.41, acc=0.883844 [time per itr] 264.02ms [lr] 0.00197
103 [train] loss=0.348 [val] loss=0.345, pp=1.41, acc=0.882837 [time per itr] 267.02ms [lr] 0.00197
104 [train] loss=0.349 [val] loss=0.344, pp=1.41, acc=0.883130 [time per itr] 266.75ms [lr] 0.00197
105 [train] loss=0.337 [val] loss=0.348, pp=1.42, acc=0.880408 [time per itr] 263.78ms [lr] 0.00197
106 [train] loss=0.341 [val] loss=0.343, pp=1.41, acc=0.882928 [time per itr] 264.73ms [lr] 0.00197
107 [train] loss=0.353 [val] loss=0.342, pp=1.41, acc=0.883514 [time per itr] 262.66ms [lr] 0.00197
108 [train] loss=0.350 [val] loss=0.344, pp=1.41, acc=0.881799 [time per itr] 263.40ms [lr] 0.00197
109 [train] loss=0.344 [val] loss=0.341, pp=1.41, acc=0.883386 [time per itr] 263.54ms [lr] 0.00197
110 [train] loss=0.335 [val] loss=0.344, pp=1.41, acc=0.881213 [time per itr] 301.51ms [lr] 0.00197
111 [train] loss=0.345 [val] loss=0.342, pp=1.41, acc=0.882336 [time per itr] 263.78ms [lr] 0.00197
112 [train] loss=0.341 [val] loss=0.340, pp=1.41, acc=0.883221 [time per itr] 262.67ms [lr] 0.00196
113 [train] loss=0.338 [val] loss=0.343, pp=1.41, acc=0.881128 [time per itr] 264.49ms [lr] 0.00196
114 [train] loss=0.335 [val] loss=0.341, pp=1.41, acc=0.882721 [time per itr] 264.38ms [lr] 0.00196
115 [train] loss=0.339 [val] loss=0.341, pp=1.41, acc=0.882312 [time per itr] 264.21ms [lr] 0.00196
116 [train] loss=0.343 [val] loss=0.340, pp=1.41, acc=0.882605 [time per itr] 260.58ms [lr] 0.00196
117 [train] loss=0.342 [val] loss=0.341, pp=1.41, acc=0.881818 [time per itr] 265.33ms [lr] 0.00196
118 [train] loss=0.343 [val] loss=0.340, pp=1.40, acc=0.882727 [time per itr] 261.92ms [lr] 0.00196
119 [train] loss=0.332 [val] loss=0.340, pp=1.40, acc=0.882642 [time per itr] 267.97ms [lr] 0.00196
120 [train] loss=0.341 [val] loss=0.336, pp=1.40, acc=0.884039 [time per itr] 264.36ms [lr] 0.00196
121 [train] loss=0.338 [val] loss=0.339, pp=1.40, acc=0.882861 [time per itr] 267.30ms [lr] 0.00196
122 [train] loss=0.335 [val] loss=0.337, pp=1.40, acc=0.883685 [time per itr] 264.14ms [lr] 0.00196
123 [train] loss=0.331 [val] loss=0.337, pp=1.40, acc=0.883313 [time per itr] 264.63ms [lr] 0.00196
124 [train] loss=0.326 [val] loss=0.338, pp=1.40, acc=0.883307 [time per itr] 263.48ms [lr] 0.00196
125 [train] loss=0.337 [val] loss=0.338, pp=1.40, acc=0.883148 [time per itr] 267.00ms [lr] 0.00195
126 [train] loss=0.341 [val] loss=0.338, pp=1.40, acc=0.882764 [time per itr] 267.18ms [lr] 0.00195
127 [train] loss=0.337 [val] loss=0.338, pp=1.40, acc=0.882806 [time per itr] 267.06ms [lr] 0.00195
128 [train] loss=0.337 [val] loss=0.337, pp=1.40, acc=0.882922 [time per itr] 265.27ms [lr] 0.00195
129 [train] loss=0.338 [val] loss=0.338, pp=1.40, acc=0.882697 [time per itr] 264.45ms [lr] 0.00195
130 [train] loss=0.335 [val] loss=0.340, pp=1.40, acc=0.881348 [time per itr] 262.81ms [lr] 0.00195
131 [train] loss=0.337 [val] loss=0.335, pp=1.40, acc=0.884125 [time per itr] 266.83ms [lr] 0.00195
132 [train] loss=0.342 [val] loss=0.339, pp=1.40, acc=0.881543 [time per itr] 263.60ms [lr] 0.00195
133 [train] loss=0.339 [val] loss=0.336, pp=1.40, acc=0.883142 [time per itr] 263.23ms [lr] 0.00195
134 [train] loss=0.339 [val] loss=0.336, pp=1.40, acc=0.883026 [time per itr] 263.02ms [lr] 0.00195
135 [train] loss=0.338 [val] loss=0.335, pp=1.40, acc=0.883679 [time per itr] 264.38ms [lr] 0.00195
136 [train] loss=0.341 [val] loss=0.337, pp=1.40, acc=0.882306 [time per itr] 262.99ms [lr] 0.00194
137 [train] loss=0.345 [val] loss=0.337, pp=1.40, acc=0.882013 [time per itr] 261.39ms [lr] 0.00194
138 [train] loss=0.332 [val] loss=0.333, pp=1.40, acc=0.884033 [time per itr] 265.77ms [lr] 0.00194
139 [train] loss=0.330 [val] loss=0.334, pp=1.40, acc=0.883679 [time per itr] 262.29ms [lr] 0.00194
140 [train] loss=0.324 [val] loss=0.338, pp=1.40, acc=0.881012 [time per itr] 266.03ms [lr] 0.00194
141 [train] loss=0.340 [val] loss=0.336, pp=1.40, acc=0.882336 [time per itr] 270.94ms [lr] 0.00194
142 [train] loss=0.342 [val] loss=0.334, pp=1.40, acc=0.883203 [time per itr] 267.85ms [lr] 0.00194
143 [train] loss=0.331 [val] loss=0.333, pp=1.40, acc=0.883661 [time per itr] 263.17ms [lr] 0.00194
144 [train] loss=0.350 [val] loss=0.334, pp=1.40, acc=0.883032 [time per itr] 271.65ms [lr] 0.00194
145 [train] loss=0.332 [val] loss=0.336, pp=1.40, acc=0.881512 [time per itr] 265.21ms [lr] 0.00194
146 [train] loss=0.330 [val] loss=0.335, pp=1.40, acc=0.882043 [time per itr] 263.42ms [lr] 0.00193
147 [train] loss=0.332 [val] loss=0.331, pp=1.39, acc=0.884357 [time per itr] 264.47ms [lr] 0.00193
148 [train] loss=0.336 [val] loss=0.334, pp=1.40, acc=0.882520 [time per itr] 264.12ms [lr] 0.00193
149 [train] loss=0.326 [val] loss=0.334, pp=1.40, acc=0.882697 [time per itr] 262.64ms [lr] 0.00193
150 [train] loss=0.329 [val] loss=0.332, pp=1.39, acc=0.883820 [time per itr] 264.41ms [lr] 0.00193
151 [train] loss=0.335 [val] loss=0.333, pp=1.40, acc=0.882373 [time per itr] 265.16ms [lr] 0.00193
152 [train] loss=0.333 [val] loss=0.331, pp=1.39, acc=0.883795 [time per itr] 265.26ms [lr] 0.00193
153 [train] loss=0.333 [val] loss=0.333, pp=1.39, acc=0.882599 [time per itr] 266.89ms [lr] 0.00193
154 [train] loss=0.337 [val] loss=0.333, pp=1.40, acc=0.882483 [time per itr] 264.35ms [lr] 0.00193
155 [train] loss=0.327 [val] loss=0.334, pp=1.40, acc=0.882269 [time per itr] 263.92ms [lr] 0.00193
156 [train] loss=0.330 [val] loss=0.334, pp=1.40, acc=0.882098 [time per itr] 265.66ms [lr] 0.00192
157 [train] loss=0.342 [val] loss=0.331, pp=1.39, acc=0.883142 [time per itr] 263.58ms [lr] 0.00192
158 [train] loss=0.332 [val] loss=0.333, pp=1.39, acc=0.882245 [time per itr] 262.77ms [lr] 0.00192
159 [train] loss=0.330 [val] loss=0.333, pp=1.39, acc=0.882758 [time per itr] 263.72ms [lr] 0.00192
160 [train] loss=0.332 [val] loss=0.333, pp=1.39, acc=0.882416 [time per itr] 265.57ms [lr] 0.00192
161 [train] loss=0.336 [val] loss=0.333, pp=1.39, acc=0.882037 [time per itr] 262.42ms [lr] 0.00192
162 [train] loss=0.337 [val] loss=0.334, pp=1.40, acc=0.881323 [time per itr] 262.18ms [lr] 0.00192
163 [train] loss=0.334 [val] loss=0.331, pp=1.39, acc=0.882880 [time per itr] 266.33ms [lr] 0.00192
164 [train] loss=0.333 [val] loss=0.334, pp=1.40, acc=0.881232 [time per itr] 263.95ms [lr] 0.00192
165 [train] loss=0.330 [val] loss=0.332, pp=1.39, acc=0.882684 [time per itr] 262.91ms [lr] 0.00191
166 [train] loss=0.329 [val] loss=0.334, pp=1.40, acc=0.880884 [time per itr] 266.19ms [lr] 0.00191
167 [train] loss=0.338 [val] loss=0.331, pp=1.39, acc=0.882739 [time per itr] 265.82ms [lr] 0.00191
168 [train] loss=0.324 [val] loss=0.332, pp=1.39, acc=0.882513 [time per itr] 281.40ms [lr] 0.00191
169 [train] loss=0.332 [val] loss=0.333, pp=1.39, acc=0.881592 [time per itr] 263.44ms [lr] 0.00191
170 [train] loss=0.336 [val] loss=0.329, pp=1.39, acc=0.884131 [time per itr] 266.20ms [lr] 0.00191
171 [train] loss=0.319 [val] loss=0.331, pp=1.39, acc=0.882709 [time per itr] 271.47ms [lr] 0.00191
Traceback (most recent call last):
  File "/mlbio_scratch/ekbote/Markov/Markov-LLM-depth/src/main.py", line 151, in <module>
    main(args)
  File "/mlbio_scratch/ekbote/Markov/Markov-LLM-depth/src/main.py", line 133, in main
    stats = train(model, opt, P, order, scheduler, args.iterations, args.acc_steps, args.batch_size, args.sequence_length, generator,
  File "/mlbio_scratch/ekbote/Markov/Markov-LLM-depth/src/optim/base.py", line 55, in train_base
    val_acc, val_loss, val_perplexity = eval(model, P, order, sequence_length, batch_size,
  File "/home/ekbote/.conda/envs/torch-2.4/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/mlbio_scratch/ekbote/Markov/Markov-LLM-depth/src/optim/utils.py", line 59, in eval
    x, y = get_batch(P, order, sequence_length, batch_size, generator, extra_args, device=device)
  File "/mlbio_scratch/ekbote/Markov/Markov-LLM-depth/src/optim/utils.py", line 37, in get_batch
    data[:,i] = get_next_symbols(P, order, data[:,i-order:i])
  File "/mlbio_scratch/ekbote/Markov/Markov-LLM-depth/src/optim/utils.py", line 43, in get_next_symbols
    def get_next_symbols(P, order, data):
KeyboardInterrupt